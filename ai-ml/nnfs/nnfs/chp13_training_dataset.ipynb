{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f142efcd",
   "metadata": {},
   "source": [
    "### Training Dataset\n",
    "\n",
    "We usually want to do some **preprocessing** to out training data, but remember that any preprocessing we do needs to be done on all future data (validation, testing, predicition) as well to ensure everything is in the same frame of reference.\n",
    "\n",
    "Neural netowkrs usually perform best on data in the range 0 to 1, or -1 to 1 (-1 to 1 is preferred). Centering the data on 0 can help with model training.\n",
    "\n",
    "In cases where we do not have many training examples, we could use **data augmentation**. For example, we can take images and rotate/crop them and use those as data as well. Be sure to only use augmentations of the data that will be seen in reality. \n",
    "\n",
    "Usually we need a few thousand samples to train a model, but it really depends on the complexity and model size. The more complex the model, the more training data you will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e390569b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
